{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "330d4f1c-7e0d-4799-9664-ac9b35ffa342",
   "metadata": {},
   "source": [
    "# Similarity Search for Fuzzy Matching Use-Case\n",
    "\n",
    "This notebook introduces the goal of outlining the primary task of deduplicating customer account data by leveraging text embeddings methods and semantic similarity matching. Synthetic data with the following column information is used: 'temp_cust_id', 'business_name_hash_key', 'address_hash_key', 'business_name', 'line1', 'line2', 'city', 'state', 'zip', 'zip_ext', 'country', 'gpc1_source_id'\n",
    "\n",
    "### The steps performed include:\n",
    "* Parameters, variables, and any helper functions are defined\n",
    "* Sample pre-processing to deduplicate initial data; Combine and transform relevant data columns\n",
    "* Apply text embeddings using REST requests\n",
    "* Create and Deploy Index for Vector Search\n",
    "* Query Index and get Ranked Results that map back to original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027985a0-f499-4862-953c-981886b73fac",
   "metadata": {},
   "source": [
    "### Import Libraries & Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc870ec-f03a-47d1-80e5-25991994c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install the packages\n",
    "# ! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
    "#                                  google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9cf7ff3-c38b-422e-8690-d96ea0f445f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import google.auth.transport.requests\n",
    "import google.auth\n",
    "from google.cloud import storage\n",
    "import requests\n",
    "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import \\\n",
    "    Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f420b831-e725-49c0-b3c1-d48fa999f79b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"sandbox-401718\" # @param\n",
    "REGION = \"us-central1\" # @param\n",
    "BUCKET_URI = f\"gs://{PROJECT_ID}-fuzzymatch-textembedding-{REGION}\"\n",
    "INPUT_URI = f\"{BUCKET_URI}/input-test\"\n",
    "OUTPUT_URI = f\"{BUCKET_URI}/output-test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e895728e-5961-4d93-a6fe-65cc6f295288",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d63b91-2393-487a-9b04-252b1e1888c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://sandbox-401718-fuzzymatch-textembedding-us-central1/...\n"
     ]
    }
   ],
   "source": [
    "# ! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f915a0b-0b1f-46f1-bc53-912fc9459014",
   "metadata": {},
   "source": [
    "## Pre-processing Logic to deduplicate data\n",
    "\n",
    "Preprocess involves cleaning, transforming, and standardizing the raw data to reduce noise and inconsistencies. Preprocessing can help ensure optimal performance and accurate results for downstream matching algorithms.\n",
    "\n",
    "Sample preprocessing techniques to consider:\n",
    "* Remove exact duplicate records (included below) \n",
    "* Normalize keyword variations in spelling and abbreviations (e.g., \"Ave\" to \"Avenue\")\n",
    "* Ensure consistent formatting across all data points\n",
    "* Identify and correct invalid or inaccurate domain information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6693214a-49b5-4959-8006-eb4816788c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('synthetic-data.csv')\\\n",
    "# .head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b3f8b90-d21f-4c9b-af9b-d2c11574b1c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_hashed = df\n",
    "\n",
    "# Create a boolean mask indicating duplicate rows based on hashed columns.\n",
    "duplicate_mask = df_hashed.duplicated(subset=['business_name_hash_key', 'address_hash_key'])\n",
    "\n",
    "# Invert the mask to select non-duplicate rows.\n",
    "unique_mask = ~duplicate_mask\n",
    "\n",
    "# Create a new DataFrame with only unique rows.\n",
    "df_hashed_unique = df_hashed[unique_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61a1c5e1-8de4-464d-806f-48dfa90facce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in original DataFrame: 100000\n",
      "Number of rows in de-duplicated DataFrame: 99769\n",
      "Number of duplicate rows removed: 231\n"
     ]
    }
   ],
   "source": [
    "original_rows = len(df)\n",
    "unique_rows = len(df_hashed_unique)\n",
    "num_duplicates = original_rows - unique_rows\n",
    "\n",
    "print(\"Number of rows in original DataFrame:\", original_rows)\n",
    "print(\"Number of rows in de-duplicated DataFrame:\", unique_rows)\n",
    "print(\"Number of duplicate rows removed:\", num_duplicates)\n",
    "\n",
    "df = df_hashed_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b4684-b740-476a-b086-3b9720a05f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be594344-bb82-47dc-b8b4-892ba437762e",
   "metadata": {},
   "source": [
    "## Textembeddings on GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee211b2-efa2-4d42-b9da-43eb50c51d24",
   "metadata": {},
   "source": [
    "### Combine and transform relevant data columns\n",
    "\n",
    "Engineer data to be optimized for embedding generation. For instance, merge granular address components like zip code and city into a unified address field to enhance semantic representation during embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3ea3eb02-148c-4af7-9bb3-c57e4bfb8be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the Address column, handling NaN in line2 and zip_ext and including business_name\n",
    "\n",
    "df[\"Address\"] = df.apply(\n",
    "    lambda row: f\"{row['business_name']}, {row['line1']} {row['line2'] if not pd.isna(row['line2']) else ''}, \"\n",
    "    f\"{row['city']}, {row['state']} \"\n",
    "    f\"{row['zip']}{'-' + row['zip_ext'] if not pd.isna(row['zip_ext']) else ''}, \"\n",
    "    f\"{row['country']}\".strip(),\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4cb6e423-9db2-4c1a-8a08-e855cd25f01f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create JSON file\n",
    "# Create a list of dictionaries from the 'Address' column\n",
    "address_data = [{\"content\": address} for address in df['Address']]\n",
    "\n",
    "# Save to a JSONL file\n",
    "with open('input.jsonl', 'w') as outfile:\n",
    "    for entry in address_data:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "72532a34-93f6-425f-8ab7-4abd60144567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded to cloud storage in gs://sandbox-401718-fuzzymatch-textembedding-us-central1/input-test\n"
     ]
    }
   ],
   "source": [
    "# save to GCS \n",
    "storage_client = storage.Client()\n",
    "\n",
    "BUCKET_NAME = \"/\".join(INPUT_URI.split(\"/\")[:3])\n",
    "bucket = storage_client.bucket(BUCKET_NAME[5:])\n",
    "\n",
    "# Define the blob including any folders from INPUT_URI\n",
    "blob_name = \"/\".join(INPUT_URI.split(\"/\")[3:])+\"/input.jsonl\"\n",
    "blob = bucket.blob(blob_name)\n",
    "\n",
    "# Upload the file \n",
    "blob.upload_from_filename(\"input.jsonl\")\n",
    "\n",
    "print(f\"File uploaded to cloud storage in {INPUT_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820b5e2-d866-4500-b0ee-5b8668bfefe7",
   "metadata": {},
   "source": [
    "### REST request for Batch Prediction Job\n",
    "\n",
    "This section details the code that makes the API request to Vertex AI to generate the text embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b742112-7297-47f8-9b02-58119ec4d6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Credentials\n",
    "\n",
    "# Set up Application Default Credentials (ADC)\n",
    "credentials, project_id = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "credentials.refresh(auth_req)\n",
    "access_token = credentials.token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "764e1a7e-a8d5-4db4-8218-40592fbf7970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = \"publishers/google/models/text-embedding-004\"\n",
    "url = f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/us-central1/batchPredictionJobs\"\n",
    "\n",
    "headers = {\n",
    "        'Authorization': 'Bearer ' + access_token,\n",
    "        'Content-Type': 'application/json; charset=utf-8'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5ec2d587-a728-43ed-880a-0fa5b57074e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request_body = str(\n",
    "    {\n",
    "        \"name\": \"batch-test\",\n",
    "        \"displayName\": \"batch-test\",\n",
    "        \"model\": MODEL,\n",
    "        \"inputConfig\": {\n",
    "            \"instancesFormat\": \"jsonl\",\n",
    "            \"gcs_source\": {\"uris\": [f\"{INPUT_URI}/input.jsonl\"]},\n",
    "        },\n",
    "        \"outputConfig\": {\n",
    "            \"predictionsFormat\": \"jsonl\",\n",
    "            \"gcs_destination\": {\"output_uri_prefix\": OUTPUT_URI},\n",
    "        },\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f4769e5c-eff4-4d47-89fb-68c89ff6e15a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# request_body = '{\"name\": \"test\", \"displayName\": \"test\", \"model\": \"publishers/google/models/text-embedding-004\", \"inputConfig\": {\"instancesFormat\": \"jsonl\", \"gcs_source\": {\"uris\": [\"gs://sandbox-401718-fuzzymatch-textembedding/input-test/input.jsonl\"]}}, \"outputConfig\": {\"predictionsFormat\": \"jsonl\", \"gcs_destination\": {\"output_uri_prefix\": \"gs://sandbox-401718-fuzzymatch-textembedding/output-test\"}}}'\n",
    "r = requests.post(url, data=request_body, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dbbd4f2e-6035-48a2-869f-59546f16907b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "be44333e-2fc7-4981-a7b2-08be56d2b145",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n  \"name\": \"projects/757654702990/locations/us-central1/batchPredictionJobs/4021747624389378048\",\\n  \"displayName\": \"test\",\\n  \"model\": \"publishers/google/models/text-embedding-004\",\\n  \"inputConfig\": {\\n    \"instancesFormat\": \"jsonl\",\\n    \"gcsSource\": {\\n      \"uris\": [\\n        \"gs://sandbox-401718-fuzzymatch-textembedding-us-central1/input-test/input.jsonl\"\\n      ]\\n    }\\n  },\\n  \"outputConfig\": {\\n    \"predictionsFormat\": \"jsonl\",\\n    \"gcsDestination\": {\\n      \"outputUriPrefix\": \"gs://sandbox-401718-fuzzymatch-textembedding-us-central1/output-test\"\\n    }\\n  },\\n  \"state\": \"JOB_STATE_PENDING\",\\n  \"createTime\": \"2024-07-03T04:16:45.381697Z\",\\n  \"updateTime\": \"2024-07-03T04:16:45.381697Z\",\\n  \"modelVersionId\": \"1\"\\n}\\n'\n"
     ]
    }
   ],
   "source": [
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb13b1-df17-4466-ab31-d6d93c7e9c7f",
   "metadata": {},
   "source": [
    "### Import JSON From Path and Map\n",
    "\n",
    "This section outlines the steps of retrieving the generated embeddings files from the Batch Job output and creating a mapping to tie it back to the respective accounts in the original data. Users are to specify the output embeddings files.\n",
    "\n",
    "* Download embed file: The embedding results from the batch prediction job are downloaded from GCS.\n",
    "* Map embeddings to original dataset: The downloaded embeddings are associated with their corresponding addresses in the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "54ee491e-b8c6-46cc-bcc3-024ba73ed308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined JSON Lines data saved to `embeddings.jsonl`\n"
     ]
    }
   ],
   "source": [
    "EMBED_FILES = [\n",
    "    \"gs://sandbox-401718-fuzzymatch-textembedding-us-central1/output-test/prediction-model-2024-07-03T04:16:45.355581Z/000000000000.jsonl\",  # @param\n",
    "    \"gs://sandbox-401718-fuzzymatch-textembedding-us-central1/output-test/prediction-model-2024-07-03T04:16:45.355581Z/000000000001.jsonl\",\n",
    "]\n",
    "\n",
    "# Write to the local JSON Lines file directly\n",
    "with open(\"embeddings.jsonl\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for embed_file in EMBED_FILES:\n",
    "        bucket_name = embed_file.split(\"/\")[2]\n",
    "        blob_name = \"/\".join(embed_file.split(\"/\")[3:])\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "\n",
    "        # Download the entire file as a string\n",
    "\n",
    "        file_content = blob.download_as_string().decode(\"utf-8\")\n",
    "        lines = file_content.splitlines()\n",
    "        for line in lines:\n",
    "            outfile.write(line + \"\\n\")  # Write each line as a separate JSON object\n",
    "print(f\"Combined JSON Lines data saved to `embeddings.jsonl`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd215696-ff59-4792-a762-705245cd8e35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the JSON data from your local .jsonl file\n",
    "response_json = []\n",
    "with open(\"embeddings.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        response_json.append(json.loads(line))  # Parse each line\n",
    "\n",
    "# Create a dictionary to map addresses to embeddings\n",
    "address_embedding_map = {}\n",
    "for item in response_json:\n",
    "    address = item['instance']['content']\n",
    "    embedding = item['predictions'][0]['embeddings']['values'] \n",
    "    address_embedding_map[address] = embedding\n",
    "\n",
    "# Map embeddings to the DataFrame using the address lookup\n",
    "df['Embeddings'] = df['Address'].map(address_embedding_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a16454-6931-4957-a11a-e52178decc3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head() # Embeddings column now included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af100bfb-e053-4ac2-9a82-144749934e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique id's\n",
    "unique_cust_ids = df['temp_cust_id'].unique()\n",
    "len(unique_cust_ids) == len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cbf52b-0c72-4d92-b202-66f09b79755b",
   "metadata": {},
   "source": [
    "## Create Index for Vector Search\n",
    "\n",
    "This section describes the process of creating an index for Vertex Vector Search. Bruce force (exhaustive) search index is used in this example, and is used to find the exact nearest neighbors to the query vector. Brute force Index is computationally rigorous compared to ANN which is focuses on performant approximations and retrieval efficiency.\n",
    "\n",
    "For more information about the methods and their tradeoff: https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a778cee7-8628-4e44-9386-c0725e6d3bcc",
   "metadata": {},
   "source": [
    "### Format data\n",
    "https://cloud.google.com/vertex-ai/docs/vector-search/setup/format-structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da08445f-976c-4c1f-a8d7-70c64e11e279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of dictionaries (same as before)\n",
    "data = []\n",
    "for index, row in df.iterrows(): \n",
    "    data.append({\n",
    "        \"id\": str(row['temp_cust_id']),\n",
    "        \"embedding\": row['Embeddings'],\n",
    "        # \"address_hash_key\": row['address_hash_key']\n",
    "    })\n",
    "    \n",
    "# Export the data as a JSON Lines file\n",
    "with open(\"index_input_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in data:\n",
    "        json.dump(entry, f)  # Write each dictionary as JSON\n",
    "        f.write('\\n')        # Add a newline to separate objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c128b53c-c2da-4deb-8f0a-f813263d7bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded to cloud storage in gs://sandbox-401718-fuzzymatch-textembedding-us-central1/input-test/initial/\n"
     ]
    }
   ],
   "source": [
    "# save to GCS \n",
    "BUCKET_NAME = \"/\".join(INPUT_URI.split(\"/\")[:3])\n",
    "bucket = storage_client.bucket(BUCKET_NAME[5:])\n",
    "\n",
    "# Define the blob including any folders from INPUT_URI\n",
    "blob_name = \"/\".join(INPUT_URI.split(\"/\")[3:])+\"/initial/index_input_data.json\"\n",
    "blob = bucket.blob(blob_name)\n",
    "\n",
    "# Upload the file \n",
    "blob.upload_from_filename(\"index_input_data.json\")\n",
    "\n",
    "print(f\"File uploaded to cloud storage in {INPUT_URI}/initial/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a5f620-b8ee-49fb-b264-1493e7568b1f",
   "metadata": {},
   "source": [
    "### Create Index\n",
    "\n",
    "For similarity calculations, the documentation strongly recommends using DOT_PRODUCT_DISTANCE + UNIT_L2_NORM instead of the COSINE distance. These algorithms have been more optimized for the DOT_PRODUCT distance, and when combined with UNIT_L2_NORM, offers the same ranking and mathematical equivalence as the COSINE distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "47893c22-220e-45c5-8b33-200bb1cd7d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=INPUT_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0e90dec7-df63-4cff-a14d-16acac50ee24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIMENSIONS = len(df[\"Embeddings\"][0])\n",
    "DISPLAY_NAME = \"index_fuzzy_match\"\n",
    "DISPLAY_NAME_BRUTE_FORCE = DISPLAY_NAME + \"_brute_force\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "91986364-3ccd-40d4-b985-a6c4c3b0979b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/757654702990/locations/us-central1/indexes/7759715352098897920/operations/3180206300940206080\n",
      "MatchingEngineIndex created. Resource name: projects/757654702990/locations/us-central1/indexes/7759715352098897920\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/757654702990/locations/us-central1/indexes/7759715352098897920')\n"
     ]
    }
   ],
   "source": [
    "brute_force_index = aiplatform.MatchingEngineIndex.create_brute_force_index(\n",
    "    display_name=DISPLAY_NAME_BRUTE_FORCE,\n",
    "    contents_delta_uri=f\"{INPUT_URI}/initial/\",\n",
    "    dimensions=DIMENSIONS,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    feature_norm_type=\"UNIT_L2_NORM\",\n",
    "    description=\"Fuzzy Match index (brute force)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1c6bc6e6-3e09-478a-b582-d2d36c5f14bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_BRUTE_FORCE_RESOURCE_NAME = brute_force_index.resource_name #'projects/757654702990/locations/us-central1/indexes/9080369554546229248'\n",
    "\n",
    "brute_force_index = aiplatform.MatchingEngineIndex(\n",
    "    index_name=INDEX_BRUTE_FORCE_RESOURCE_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353e9bda-a2f5-46fc-af50-8481d982ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "#     display_name=DISPLAY_NAME,\n",
    "#     contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
    "#     dimensions=DIMENSIONS,\n",
    "#     approximate_neighbors_count=150,\n",
    "#     distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "#     leaf_node_embedding_count=500,\n",
    "#     leaf_nodes_to_search_percent=7,\n",
    "#     description=\"Glove 100 ANN index\",\n",
    "#     labels={\"label_name\": \"label_value\"},\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6dee79-d066-4052-8fb7-bc4393ccf8ca",
   "metadata": {},
   "source": [
    "### Deploy Index to Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cdfd4be8-f2ed-40b3-ac8d-7f31de6d1747",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the project number\n",
    "PROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
    "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
    "# PROJECT_NUMBER = 757654702990\n",
    "\n",
    "VPC_NETWORK = \"beusebio-network\"\n",
    "VPC_NETWORK_FULL = f\"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f178ec1b-b920-4f47-8243-82fd9f2754a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/757654702990/locations/us-central1/indexEndpoints/4631376072657600512/operations/3168947301871779840\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/757654702990/locations/us-central1/indexEndpoints/4631376072657600512\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/757654702990/locations/us-central1/indexEndpoints/4631376072657600512')\n"
     ]
    }
   ],
   "source": [
    "# Endpoint\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=\"index_endpoint_for_fuzzy_match\",\n",
    "    description=\"fuzzy matching index\",\n",
    "    network=VPC_NETWORK_FULL,\n",
    ")\n",
    "\n",
    "INDEX_ENDPOINT_NAME = my_index_endpoint.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fd1d3346-2e4d-4332-9b7f-3129088b2981",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index.MatchingEngineIndex object at 0x7fa10ac5d030> \n",
       "resource name: projects/757654702990/locations/us-central1/indexes/7759715352098897920"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_force_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "262fdae9-1872-4292-b4d6-5380bbd51ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/757654702990/locations/us-central1/indexEndpoints/4631376072657600512\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/757654702990/locations/us-central1/indexEndpoints/4631376072657600512/operations/3310810690133950464\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/757654702990/locations/us-central1/indexEndpoints/4631376072657600512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[id: \"fuzzy_match_brute_force_deploy_full\"\n",
       "index: \"projects/757654702990/locations/us-central1/indexes/7759715352098897920\"\n",
       "create_time {\n",
       "  seconds: 1720046077\n",
       "  nanos: 116225000\n",
       "}\n",
       "private_endpoints {\n",
       "  match_grpc_address: \"10.116.0.5\"\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1720046291\n",
       "  nanos: 278326000\n",
       "}\n",
       "automatic_resources {\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deploy\n",
    "DEPLOYED_BRUTE_FORCE_INDEX_ID = \"fuzzy_match_brute_force_deploy_full\"\n",
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=brute_force_index, deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e99ac6-ca4b-41ce-b9f6-88a53f483aa4",
   "metadata": {},
   "source": [
    "### Query and get ranked results\n",
    "Query the deployed index to find similar addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7e164f32-091b-463e-9458-c25ed77e50d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = df[\"Embeddings\"][9000] # @param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "10c5bb5e-0e10-4569-97bf-86eb848f2e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='020ec9083f20ab04cb779b8990967817', distance=0.9999999403953552, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None),\n",
       "  MatchNeighbor(id='0a1be698f1d315c5dba9b3581a931710', distance=0.9554516077041626, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None),\n",
       "  MatchNeighbor(id='0d7c94165eaf73c39cf02f01db468d2f', distance=0.7347900867462158, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None),\n",
       "  MatchNeighbor(id='0bbbb1ac1580e80eb8a800b93eaf6080', distance=0.7340426445007324, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None),\n",
       "  MatchNeighbor(id='097c65235d1a20fc7475fe933d83d66c', distance=0.7240421772003174, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None),\n",
       "  MatchNeighbor(id='15a186457d087e2379429d750eee11f4', distance=0.7237255573272705, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None),\n",
       "  MatchNeighbor(id='158a4db522b73bbb8246463653c1ebfb', distance=0.7134462594985962, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None),\n",
       "  MatchNeighbor(id='05596eb564015a5686e9d18ac268027c', distance=0.7066338658332825, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None),\n",
       "  MatchNeighbor(id='0860cd862a6d725cb3a506e817cf2ba9', distance=0.7049549221992493, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None),\n",
       "  MatchNeighbor(id='09e8fcdf9690e14a946409facc2d85a3', distance=0.7048553824424744, feature_vector=None, crowding_tag=None, restricts=None, numeric_restricts=None)]]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test query\n",
    "response = my_index_endpoint.match(\n",
    "    deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID,\n",
    "    queries=[query],\n",
    "    num_neighbors=10,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304bd431-3d82-480c-a04c-4d6e9a126780",
   "metadata": {},
   "source": [
    "### Map Response back to Address\n",
    "\n",
    "Retrieve the original addresses from the Vector Search results (which are initially provided as customer IDs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370ba3e-aa35-4d92-b809-678759423551",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_data = []\n",
    "for neighbor in response[0]:  # Accessing the inner list\n",
    "    matched_id = neighbor.id\n",
    "    distance = neighbor.distance\n",
    "    matched_address = df[df[\"temp_cust_id\"] == matched_id][\"Address\"].iloc[0]\n",
    "    matched_data.append(\n",
    "        {\"ID\": matched_id, \"Address\": matched_address, \"Distance\": distance}\n",
    "    )\n",
    "matched_df = pd.DataFrame(matched_data)\n",
    "[(address) for address in matched_df[\"Address\"]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5bbb41-e8fd-4f57-9074-cf7076592c63",
   "metadata": {},
   "source": [
    "### Considerations for Refining and Improving the Fuzzy Matching Results\n",
    "* **Threshold Selection:**  Choose an appropriate similarity threshold to define matches, balancing accuracy and the tolerance for errors. \n",
    "* **Integration:** Seamlessly integrate this similarity search process into your existing fuzzy matching workflows and systems. \n",
    "* **Post-Processing:** Apply additional techniques and rules to refine the matching results further.\n",
    "* **Domain Heuristics:** Consider incorporating domain knowledge and rules to improve the quality of the fuzzy matching.\n",
    "* **FIne Tuning:** Fine Tune the Text Gecko Embeddings model to increase overall embedding task effectiveness."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
